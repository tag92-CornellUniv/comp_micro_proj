---
title: "Amplicon sequencing project"
author: "T. Griffin"
date: "2024-03-10"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
```{r load-libraries}
#going to get the environment setup
#install.packages("tidyverse")
#install.packages("devtools")
#install.packages("patchwork")
library("devtools")
#devtools::install_github("benjjneb/dada2", ref="v1.16")
library(dada2)
library(tidyverse)
library(ggplot2)
library(patchwork)
```

```{r load-data}
#I am going to give my raw sequences an object name so that I can use them in the analysis

raw_fastq_seq <- "/local/workdir/tag92/git_repos/comp_micro_proj/ncbi_data/fastq_files"
raw_fastq_seq

#intuition check
head(list.files(raw_fastq_seq))

str(list.files(raw_fastq_seq))

```

```{r vectors-for-F-and-R-Reads}

forward_reads <- list.files(raw_fastq_seq, pattern = "_1.fastq.gz", full.names = TRUE)
head(forward_reads)

reverse_reads <- list.files(raw_fastq_seq, pattern = "_2.fastq.gz", full.names = TRUE)
head(reverse_reads)
```

```{r quality-check}

random_samples <- sample(1:length(reverse_reads), size = 12)
random_samples

forward_filteredQual_plot_12 <- plotQualityProfile(forward_reads[random_samples]) + 
  labs(title = "Forward Read: Raw Quality")

reverse_filteredQual_plot_12 <- plotQualityProfile(reverse_reads[random_samples]) + 
  labs(title = "Reverse Read: Raw Quality")

forward_filteredQual_plot_12 
reverse_filteredQual_plot_12

#plot both together using patchwork
forward_filteredQual_plot_12 + reverse_filteredQual_plot_12

#aggregate the plots
forward_preQC_plot <- 
  plotQualityProfile(forward_reads, aggregate = TRUE) + 
  labs(title = "Forward Pre-QC")

reverse_preQC_plot <- 
  plotQualityProfile(reverse_reads, aggregate = TRUE) + 
  labs(title = "Reverse Pre-QC")

preQC_aggregate_plot <- 
  forward_preQC_plot + reverse_preQC_plot

preQC_aggregate_plot

```

```{r placeholders}

samples <- sapply(strsplit(basename(forward_reads), "_"), `[`,1) 
head(samples)

#filter the reads into their own folder
filtered_fastqs_path <- "local/workdir/tag92/git_repos/comp_micro_proj/ncbi_data/fastq_files/filtered_fastqs"
filtered_fastqs_path

filtered_forward_reads <- 
  file.path(filtered_fastqs_path, paste0(samples, "_1.fastq.gz"))
length(filtered_forward_reads)
head(filtered_forward_reads)

filtered_reverse_reads <- 
  file.path(filtered_fastqs_path, paste0(samples, "_2.fastq.gz"))
length(filtered_reverse_reads)
head(filtered_reverse_reads)

```

```{r filter-and-trim}
filtered_reads <- 
  filterAndTrim(fwd = forward_reads, filt = filtered_forward_reads,
              rev = reverse_reads, filt.rev = filtered_reverse_reads,
              maxN = 0, maxEE = c(1,1), trimLeft = 15, truncQ = 2, truncLen = c(250, 200), rm.phix = TRUE, compress = TRUE, multithread = TRUE)

```

```{r trimmed-read-quality}
forward_filteredQual_plot_12 <- 
  plotQualityProfile(filtered_forward_reads[random_samples]) + 
  labs(title = "Trimmed Forward Read Quality")

reverse_filteredQual_plot_12 <- 
  plotQualityProfile(filtered_reverse_reads[random_samples]) + 
  labs(title = "Trimmed Reverse Read Quality")

forward_filteredQual_plot_12 + reverse_filteredQual_plot_12


forward_postQC_plot <- 
  plotQualityProfile(filtered_forward_reads, aggregate = TRUE) + 
  labs(title = "Forward Post-QC")

reverse_postQC_plot <- 
  plotQualityProfile(filtered_reverse_reads, aggregate = TRUE) + 
  labs(title = "Reverse Post-QC")

postQC_aggregate_plot <- forward_postQC_plot + reverse_postQC_plot

postQC_aggregate_plot
```

```{r stats-on-read-output}
filtered_df <- as.data.frame(filtered_reads)
head(filtered_df)


filtered_df %>%
reframe(median_reads_in = median(reads.in),
 median_reads_out = median(reads.out),
  median_percent_retained = (median(reads.out)/median(reads.in)))

#compare pre vs post QC
preQC_aggregate_plot / postQC_aggregate_plot
```

```{r error-modeling}
#run on the forward reads
error_forward_reads <- 
  learnErrors(filtered_forward_reads) 

#run on the reverse reads
error_reverse_reads <- 
  learnErrors(filtered_reverse_reads) 

plotErrors(error_forward_reads, nominalQ = TRUE) + 
  labs(title = "Forward Read Error Model")

plotErrors(error_reverse_reads, nominalQ = TRUE) + 
  labs(title = "Reverse Read Error Model")


```

```{r infer-asvs}
dada_forward <- dada(filtered_forward_reads,
                     err = error_forward_reads, 
                     multithread = TRUE)

dada_reverse <- dada(filtered_reverse_reads,
                     err = error_reverse_reads, 
                     multithread = TRUE)
dada_reverse[1]

```

```{r merge-forward-and-reverse-reads}

#merge forward and reverse ASVs
merged_ASVs <- mergePairs(dada_forward, filtered_forward_reads,
                          dada_reverse, filtered_reverse_reads,
                          verbose = TRUE)

#Evaluate the output 
typeof(merged_ASVs)
length(merged_ASVs)
names(merged_ASVs)
```

```{r}
head(merged_ASVs[[3]])
```

```{r raw-ASV-count-table}
raw_ASV_table <- makeSequenceTable(merged_ASVs)
dim(raw_ASV_table)

table(nchar(getSequences(raw_ASV_table)))

data.frame(Seq_Length = nchar(getSequences(raw_ASV_table))) %>%
  ggplot(aes(x = Seq_Length )) + 
  geom_histogram() + 
  labs(title = "Raw distribution of ASV length")

#trim the asvs to a preferrable length
raw_ASV_table_trimmed <- raw_ASV_table[,nchar(colnames(raw_ASV_table)) %in% 285:287]
#check to see if it worked
table(nchar(getSequences(raw_ASV_table_trimmed)))

sum(raw_ASV_table_trimmed)/sum(raw_ASV_table)

data.frame(Seq_Length = nchar(getSequences(raw_ASV_table_trimmed))) %>%
  ggplot(aes(x = Seq_Length )) + 
  geom_histogram() + 
  labs(title = "Trimmed distribution of ASV length")
```

```{r remove-chimeras}
noChimeras_ASV_table <- removeBimeraDenovo(raw_ASV_table_trimmed, 
                                           method="consensus", 
                                           multithread=TRUE, verbose=TRUE)
dim(noChimeras_ASV_table)

#Tells you the proportion of sequences that are left after removing the chimeras

sum(noChimeras_ASV_table)/sum(raw_ASV_table_trimmed)

data.frame(Seq_Length_NoChim = nchar(getSequences(noChimeras_ASV_table))) %>%
  ggplot(aes(x = Seq_Length_NoChim )) + 
  geom_histogram()+ 
  labs(title = "Trimmed + Chimera Removal distribution of ASV length")

#The value was originally at like 4000 but is now at 3000



```

```{r looking-at-remaining-reads}

getN <- function(x) sum(getUniques(x))

track <- cbind(filtered_reads, 
               sapply(dada_forward, getN),
               sapply(dada_reverse, getN),
               sapply(merged_ASVs, getN),
               rowSums(noChimeras_ASV_table))
#I think this is showing the lost reads at each step
head(track)


colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")
rownames(track) <- samples

track_counts_df <- 
  track %>%
 
  as.data.frame() %>%
  rownames_to_column(var = "names") %>%
  mutate(perc_reads_retained = 100 * nochim / input)

track_counts_df %>%
  pivot_longer(input:nochim, names_to = "read_type", values_to = "num_reads") %>%
  mutate(read_type = fct_relevel(read_type, 
                                 "input", "filtered", "denoisedF", "denoisedR", "merged", "nochim")) %>%
  ggplot(aes(x = read_type, y = num_reads, fill = read_type)) + 
  geom_line(aes(group = names), color = "grey") + 
  geom_point(shape = 21, size = 3, alpha = 0.8) + 
  scale_fill_brewer(palette = "Spectral") + 
  labs(x = "Filtering Step", y = "Number of Sequences") + 
  theme_bw()
```

```{r tax-assignment}
taxa_train <- 
  assignTaxonomy(noChimeras_ASV_table, 
                 "/workdir/in_class_data/taxonomy/silva_nr99_v138.1_train_set.fa.gz", 
                 multithread=TRUE)

taxa_addSpecies <- 
  addSpecies(taxa_train, 
             "/workdir/in_class_data/taxonomy/silva_species_assignment_v138.1.fa.gz")

taxa_print <- taxa_addSpecies
rownames(taxa_print) <- NULL

view(taxa_print)
```

```{r final-asv-table}
#we are going to make this more readable with headers
asv_seqs <- colnames(noChimeras_ASV_table)
asv_seqs[1:5]

asv_headers <- vector(dim(noChimeras_ASV_table)[2], mode = "character")
asv_headers[1:5]

for (i in 1:dim(noChimeras_ASV_table)[2]) {
  asv_headers[i] <- paste(">ASV", i, sep = "_")
}

asv_headers[1:5]

asv_tab <- t(noChimeras_ASV_table)
View(asv_tab)

row.names(asv_tab) <- sub(">", "", asv_headers)
View(asv_tab)

#I can see how many of each ASV in each sample

```

```{r taxonomy-table}

#making a taxonomy table

View(taxa_addSpecies)

new_tax_tab <- 
  taxa_addSpecies%>%
  as.data.frame() %>%
  rownames_to_column(var = "ASVseqs") 
head(new_tax_tab)
view(new_tax_tab)

rownames(new_tax_tab) <- rownames(asv_tab)
head(new_tax_tab)
view(new_tax_tab)

#this will move the asv seqs
asv_tax <- 
  new_tax_tab %>%
  mutate(ASV = rownames(asv_tab)) %>%
  dplyr::select(Kingdom, Phylum, Class, Order, Family, Genus, Species, ASV, ASVseqs)

head(asv_tax)
view(asv_tax)
```

```{r save-the-files}
write.table(asv_tab, "./output_DADA2_ASV_counts.tsv", sep = "\t", quote = FALSE, col.names = NA)
write.table(noChimeras_ASV_table, "./output_DADA2_ASV_counts_withSeqNames.tsv", sep = "\t", quote = FALSE, col.names = NA)
asv_fasta <- c(rbind(asv_headers, asv_seqs))
write(asv_fasta, "./output_DADA2_ASVs.fasta")


# Write the table 
write.table(asv_tax, "./output_DADA2_ASV_taxonomy.tsv", sep = "\t", quote = FALSE, col.names = NA)

# RData objects are for easy loading :) 
save(noChimeras_ASV_table, file = "./output_DADA2_noChimeras_ASV_table.RData")
save(asv_tab, file = "./output_DADA2_ASV_counts.RData")

save(track_counts_df, file = "./output_DADA2_track_read_counts.RData")

```

